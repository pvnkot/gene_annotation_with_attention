{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Config for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sample_size = 500\n",
    "negative_sample_size = 500\n",
    "positive_test_sample_size = 100\n",
    "negative_test_sample_size = 100\n",
    "window_size = 3\n",
    "embedding_size = 5\n",
    "num_epochs = 1\n",
    "batch_size = 50\n",
    "hidden_layer_size = 500\n",
    "hidden_layer_size_2 = 100\n",
    "with_attention = True\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading data for basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = pd.read_csv('positive_sample.txt', header = None, nrows = positive_sample_size)\n",
    "positive_data.columns = [\"Gene\"]\n",
    "negative_data = pd.read_csv('negative_sample.txt', header = None, nrows = negative_sample_size)\n",
    "negative_data.columns = [\"Gene\"]\n",
    "positive_test_data = pd.read_fwf('positive_sample_test.txt', header = None)\n",
    "positive_test_data.columns = [\"Gene\"]\n",
    "negative_test_data = pd.read_fwf('negative_sample_test.txt', header = None)\n",
    "negative_test_data.columns = [\"Gene\"]\n",
    "train_data = positive_data.append(negative_data)\n",
    "test_data = positive_test_data.append(negative_test_data)\n",
    "model_name = 'fc_with_attention.pt' if with_attention else 'fc_without_attention.pt'\n",
    "#print(data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Helper methods for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper methods\n",
    "def get_labels(positive_sample_size, negative_sample_size):\n",
    "    #labels = []\n",
    "    #positive_\n",
    "    labels = torch.cat((torch.ones([positive_sample_size, 1], dtype=torch.float), torch.zeros([negative_sample_size, 1], dtype=torch.float)))\n",
    "    #print(labels)\n",
    "    return labels\n",
    "def embeddings_helper(window_size):\n",
    "    vocab_set = set()\n",
    "    def generate_vocab_helper(set, k): \n",
    "        n = len(set)  \n",
    "        generate_vocab(set, \"\", n, k) \n",
    "    def generate_vocab(set, prefix, n, k): \n",
    "        if (k == 0) : \n",
    "            vocab_set.add(prefix)\n",
    "            return\n",
    "        for i in range(n): \n",
    "            newPrefix = prefix + set[i] \n",
    "            generate_vocab(set, newPrefix, n, k - 1) \n",
    "    def generate_embed_map(n):\n",
    "        alphabet = ['0','1','2','3','4']\n",
    "        generate_vocab_helper(alphabet, n)\n",
    "\n",
    "        vocab_set_1 = sorted(vocab_set)\n",
    "        vocab_map = {}\n",
    "\n",
    "        for i in range(len(vocab_set_1)):\n",
    "            vocab_map[vocab_set_1[i]] = i\n",
    "        return vocab_map\n",
    "    return generate_embed_map(window_size)\n",
    "\n",
    "def return_embeddings(vocabulary):\n",
    "    embeds = nn.Embedding(len(vocabulary), embedding_size)\n",
    "    embeddings = {}\n",
    "    for word in vocabulary:\n",
    "        embeddings[word] = embeds(torch.tensor(vocabulary[word], dtype=torch.long))\n",
    "    return embeddings\n",
    "\n",
    "#ATG, GTG, TTG\n",
    "def is_start_codon(codon):\n",
    "    start_codons = ['143', '343', '443']#['ATG', 'GTG', 'TTG']\n",
    "    if codon in start_codons:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create training data with training inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_and_labels(with_attention, datapoints, positive_sample_size, negative_sample_size):\n",
    "    list_of_tensors = []\n",
    "    #\n",
    "    # In an array, place 1s for codons that match the start pattern and 0s for codons that do not.\n",
    "    #\n",
    "    \n",
    "    #Creating word indexes for permutations of protein bases (words of vocabulary)\n",
    "    vocabulary = embeddings_helper(window_size)\n",
    "    embeddings = return_embeddings(vocabulary)\n",
    "    \n",
    "    codon_arr = []\n",
    "    for data in datapoints.itertuples():\n",
    "        gene = data.Gene\n",
    "\n",
    "        for i in range(len(gene) - window_size + 1):\n",
    "            codon = gene[i:i+window_size]\n",
    "            weight = 1\n",
    "            if with_attention and is_start_codon(codon):\n",
    "                weight = i+1\n",
    "            if i == 0:\n",
    "                first_tensor = embeddings[gene[i:i+window_size]] * weight\n",
    "            else:\n",
    "                first_tensor = torch.cat((first_tensor, weight * embeddings[gene[i:i+window_size]]), 0)\n",
    "\n",
    "        list_of_tensors.append(first_tensor)\n",
    "    inputs = torch.stack(list_of_tensors)\n",
    "    labels = get_labels(positive_sample_size, negative_sample_size)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Implementing the FC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_size*(len(positive_data.Gene[0]) - window_size + 1), hidden_layer_size)\n",
    "        self.relu = F.relu\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.fc2 = nn.Linear(hidden_layer_size, hidden_layer_size_2)\n",
    "        self.fc2 = nn.Linear(hidden_layer_size, 1)\n",
    "        #self.out = nn.Linear(hidden_layer_size_2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.fc1(x)\n",
    "        h1 = self.relu(a1)\n",
    "        #dout = self.dout(h1)\n",
    "        a2 = self.fc2(h1)\n",
    "        h2 = self.relu(a2)\n",
    "        #a3 = self.out(h2)\n",
    "        y = self.sigmoid(h2)\n",
    "        return y\n",
    "    \n",
    "def train_epoch(model, inputs, labels, optimizer, criterion, batch_size):\n",
    "    model.train()\n",
    "    #losses = []\n",
    "    losses = torch.zeros(len(inputs), 1)\n",
    "    labels_hat = []\n",
    "    correct, wrong = 0,0\n",
    "    for i in range(0, inputs.size(0)):\n",
    "        #data_batch = inputs[i:i + batch_size, :]\n",
    "        #labels_batch = labels[i:i + batch_size, :]\n",
    "        inputs[i] = autograd.Variable(inputs[i])\n",
    "        labels[i] = autograd.Variable(labels[i])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # (1) Forward\n",
    "        label_hat = model(inputs[i])\n",
    "        #print(labels_hat)\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(label_hat, labels[i])\n",
    "        # (3) Compute gradients\n",
    "        #losses.append(loss.data.numpy())\n",
    "        losses[i] = loss\n",
    "        loss.backward(retain_graph = True)\n",
    "        # (4) update weights\n",
    "        optimizer.step()        \n",
    "        \n",
    "#         print(loss)\n",
    "#         print('>>>>>')\n",
    "        #get_accuracy(labels_hat)\n",
    "        correct, wrong = get_train_accuracy(label_hat, len(labels_hat), len(labels), correct, wrong)\n",
    "        #labels_hat.append(label_hat)\n",
    "        #labels_hat = torch.cat(labels_hat, labels_hat_batch)\n",
    "        \n",
    "\n",
    "    #print('labels_hat size>', len(labels_hat))\n",
    "    loss = sum(losses)/len(losses)\n",
    "    \n",
    "    return loss, labels_hat, tuple((correct, wrong))\n",
    "    \n",
    "def train_model(model, inputs, labels, optimizer, criterion, with_attention, batch_size):\n",
    "    losses = []\n",
    "    labels_hat = []\n",
    "    print('Training the model:')\n",
    "    start_time = time.time()\n",
    "    accuracies = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        loss, labels_hat, acc = train_epoch(model, inputs, labels, optimizer, criterion, batch_size)\n",
    "\n",
    "        losses.append(loss)\n",
    "        #labels_hat.append(label_hat)\n",
    "        #accuracy\n",
    "        accuracy = 100*(acc[0]/(acc[0]+acc[1]))\n",
    "        accuracies.append(accuracy)\n",
    "        print('Accuracy for epoch', epoch, ' is: ', accuracy)\n",
    "#         if epoch % 25 == 0:    #print every 25 mini-batches\n",
    "#             print('[%d, %5d] loss: %.9f' %\n",
    "#                 (epoch + 1, epoch + 1, running_loss/len(inputs)))\n",
    "#             #running_loss = 0.0\n",
    "    \n",
    "    torch.save(model.state_dict(), model_name)\n",
    "    print('Finished. Training took %.3f' %((time.time() - start_time)/60), 'minutes.')\n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    fcNet = Net()\n",
    "    inputs, labels = get_inputs_and_labels(with_attention, train_data, positive_sample_size, negative_sample_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(fcNet.parameters(), lr=0.01, momentum=0.0)\n",
    "    losses, train_accuracies = train_model(fcNet, inputs, labels, optimizer, criterion, with_attention, batch_size)\n",
    "    if losses != None:\n",
    "        plt.plot(losses)\n",
    "        title = 'Loss vs Epochs for: ' + (str)(positive_sample_size + negative_sample_size) + ' data points and ' + (str)(num_epochs) + ' epochs'\n",
    "        plt.title(title)\n",
    "    return train_accuracies\n",
    "        \n",
    "        \n",
    "def test():\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    model.eval()\n",
    "\n",
    "    test_inputs, test_labels = get_inputs_and_labels(with_attention, test_data, positive_sample_size, negative_sample_size)\n",
    "    test_labels_hat = model(test_inputs)\n",
    "    accuracy = get_test_accuracy(test_labels_hat)\n",
    "    print('Accuracy is: ' , accuracy)\n",
    "    return accuracy\n",
    "#    print(correct, wrong)\n",
    "    \n",
    "def get_train_accuracy(label, index, data_size, correct, wrong):    \n",
    "    if index < data_size/2+1:\n",
    "        if label > 0.5:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    else:\n",
    "        if label > 0.5:\n",
    "            wrong += 1\n",
    "        else:\n",
    "            correct += 1\n",
    "    return correct, wrong\n",
    "\n",
    "def get_test_accuracy(labels_hat):\n",
    "    #print('Length of labels_hat:', len(labels_hat))\n",
    "    correct, wrong = 0, 0\n",
    "    #if labels_hat\n",
    "    for i in range(len(labels_hat)//2 + 1):\n",
    "        if labels_hat[i] > 0.5:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    for i in range(len(labels_hat)//2 + 1, len(labels_hat)):\n",
    "        if labels_hat[i] > 0.5:\n",
    "            wrong += 1\n",
    "        else:\n",
    "            correct += 1\n",
    "    accuracy = 100 * (correct/(correct+wrong))\n",
    "    return accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model:\n",
      "Accuracy for epoch 0  is:  49.9\n",
      "Finished. Training took 18.110 minutes.\n",
      "Accuracy is:  49.833333333333336\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGO9JREFUeJzt3XuYXHV9x/H3hwQIwWASssaQAEGhaEDBug/UChq5KKI1qSJVUCOikUdtvUA1CNrgrUBV0GrVFCxRQMALQqkPGJHUqi0SBBVEJECQhIQsmkACoqDf/vH7LTmZzOzM7szsJD8+r+eZZ89tzvn+zuUzZ845u6uIwMzMtn3b9boAMzPrDAe6mVkhHOhmZoVwoJuZFcKBbmZWCAe6mVkhHOi2BUlLJb21A/PZV9LNkjZI+odO1LYtkDRb0spe19GMpOMlfbfXdQyXpJC0d6/rGAlJCyVd2K359yzQc2isk7Rjr2rYFki6QNIfJW2svH7W67pa9H7guoiYEBGf7fTMJe0v6RpJD0ja4hcqJE2WdLmkhyXdI+m4mvHH5eEPS/q2pMmtvreDbXizpB92Y97NRMRFEfHSVqbtZZ3DIelYST+W9Iikpb2uZ7T1JNAlzQQOBQJ41Sgve+xoLq9Dzo6Ip1ReB/S6oBbtCdw6kje2uJ0eAy4DTmww/vPAH4GpwPHAFyTtl+e/H/Al4I15/CPAv7XyXtuq/Q44Fziz14X0RESM+gv4MPAj4NPAVTXjdgI+BdwDPAj8ENgpjzsE+DGwHrgXeHMevhR4a2UebwZ+WOkP4J3AHcDdedhn8jweAm4EDq1MPwb4IHAnsCGP3510kH+qpt4rgffWaeMXgE/WDLsCeF/u/gCwKs//duDwBuvqAuBjDcbNzG2bD9wHrAZOqYzfkbRz35df5wI7VsbPAW7O6+BO4KjK+vxo3kYbgO8CU/K4ccCFwG/zdrgBmFqntu8DfwIeBTYCfwE8FfgKMJC37+nAdpVt9iPgnDzvum1usB72TrvyZsN2JgXyX1SGfRU4M3d/Ari4Mu6ZefoJzd5bZ/k75e20Dvgl8I/Aysr4BZV96ZfA3+bhz87r5095Ha3Pw18B3JS3y73AwiHaPhtYSdpfHwBWAMdXxjdb57XHyUmk42Q9aX/XEHUenduzgbQvn9Kgxmfm/eG3ucaLgImV8SuAU4Cfk475S4FxlfH/SNq37wPekuvcu8k+8VZgaQv7zitJx8B6UrY8t6auU3Mb1wH/UVPX24DlpA+RK4HdKuP2A5bkcfcDH8zDF5JOQr6S19utQH/lfS3lQsP2DGfiTr3ySngH8HzSWdbUyrjPkwJlOilY/5oUTHvmRr4e2B7YFTiwEkDNAn0JMJlNHw5vyPMYC5wMrBncWHkH+gWwb96hD8jTHpR3qsEDYgrpzK5eoL2IdDAq908Cfg/slud77+AOQArmZzZYVxfQPNC/Rgqh55AO3CPy+I8A/wc8DejLO+xH87iDSAfPkaRvatOBZ1XW552kEN4p9w8G4duB/wTG5+3zfGCXBvXVbpevkD7UJuTafw2cWNlmjwN/n7fJTsAepANtjyb7U71Afx7wSM2wU4D/zN1XAB+oGb8xt2fI99ZZ/pnA/+T9a3fgFjYP9Nfm7b4d8HfAw8C0evtqHjY7b8vtgOeSAmFug2XPzuvt06Tj5MV5/vu2uM5rj5OrgIl53Q+w6UO+Xp2rySdCpP37L4fYPkfm+vqAHwDnVsavAH6S19Fk4DbgpDzuqNz+/Un7+MV0KNDzdl4LHEzal+flWnas1HVL3qaTSSccH8vjDiN9OP1lbte/Aj/I4ybkdXMy6QRoAnBwHreQ9OF4dF7mPwP/l8e1nAsN2zSciTvxIp1lP8amM75fkc9w8w78e+CAOu87Fbi8xeCot6Me1qSudYPLJX0yzmkw3W3Akbn7XcB3Gkwn4DfAi3L/24DvV3bwtcARwPZN6rog7wDrK6/FlQ0e5CDOw84Gzs/ddwJHV8a9DFiRu78EnDPE+jy90v8O4Orc/RZqzmSGqP2J7ZJ33j8Csyrj304+6PI2+80I96l6gX4osKZm2Nsqy7uWHBqV8atIATnke+ss/y5y8OX++VQCvc70Nw/uX7X7aoPpzx1iW80mBfrOlWGXAR9qcZ3XHieH1MxnQaM68/79dhp8oA/RnrnATZX+FcAbavbhL+buL1P5ZkQ6yehUoH+BfIJTGXY78OJKXSdVxh0N3Jm7zyddCh0c9xRSrs0knXTe1GCZC4HvVfpnAb+v7Mct5UKjVy+uoc8DvhsRD+T+i/MwSGe840hBVGv3BsNbdW+1R9Ipkm6T9KCk9aSvplNaWNZi0tk9+edX600UaQtdQtq4AMeRvmoSEcuB95A27lpJl0jabYjaPxkREyuveTXjq227h3SmQ/55T4Nxzdbnmkr3I6QdFlJ7rwEukXSfpLMlbT/EfAZNIX2zqq1neoN2tGsjsEvNsF1I3/KajW/23lq7seU2eIKkN+WnfdbnfW1/Nu1rW5B0sKTrJA1IepB0GaTh9MC6iHi4Zvm70do6r9Vou9fzGlLI3SPpvyW9oN5EkqbmfXyVpIdIl+xq29NouUOu2zbtCZw8uF3yttmdTccIdZZd99iKiI2kS0rTGf6xNU7S2BHkwhZGNdAl7QQcC7xY0hpJa4D3AgdIOoD0FeZR0jW3Wvc2GA7pK+b4Sv/T60wTlToOJT2BcSwwKSImki4/qIVlXQjMyfU+G/h2g+kgXQo5RtKepK9133yimIiLI+IQ0k4VwFlDzKeZ3Svde5AuC5F/7tlg3FBtbCgiHouIMyJiFuly2CuBN7Xw1gdIZzC19ayqzn649Qzh18BYSftUhh3Appu0t+Z+ACQ9g/TV+dctvLfWarbcBoPz3RP4d9K3uV3zvnYLm/a1em2+mHRNdveIeCrwxcr09UyStHPN8u+jtXXeqi3qjIgbImIO6ZLet0ln9PV8Ir//ORGxC+lEaKj2VDVctx1wL/DxmpOl8RHxtco0LR1bef3vSlq39wLPGElB7ebCaJ+hzyXdWJkFHJhfzyZdf3xTRPyZ9BXr05J2kzRG0gvyo40XAUfkx5LGStpV0oF5vjcDr5Y0Pj+f2uiph0ETSF9TB0gH7ofZ/IzsPOCjkvZR8lxJuwJExErSjcCvAt+MiN83WkhE3EQ6qM4DromI9fDE89mH5XY9SrrM9Ofmq6+hD+W27wecQLqpBOkD5XRJfZKmkG5GDz4Dez5wgqTDJW0nabqkZzVbkKSXSHqOpDGkm3aPtVJ7RPyJdMB/XNKEHHTvq9QzbHnbjAN2yP3j8joln7F+C/iIpJ0lvZB0E3jwG9VFwN9IOjQfjB8BvhURG1p4b63LgFMlTZI0g3QfYNDOpANzINd4AukMfdD9wAxJO1SGTQB+FxGPSjqI9O2umTMk7ZBPVl4JfL3D63yzOvOyjpf01Ih4jLQvNNoPJpC+9TwoaTrpHlWrLgPeLGmWpPHAPw01cc6McaT7MNvlfaLRN8h/B07K34iUt/UrJE2oTPNOSTOUHmk9jc2PrRMkHZj3uU8A10fECtJ9iGmS3iNpx7zuD27W0I7kwkiu04z0BVxNzVMiefixpK8hgzfDziV90j1IuoEyeCPzUOB6Nt39n5eHTyE9ibGBdONiIVteG9y70j+G9MHxEOkM4P2k62VHVMafDtyd53kDMKPy/jfkeb6khTZ/KE/72sqw55JuAm0g3QW/isod8pr3X0C6Drqx8nogj5vJ5k+5rAHeX3nvOOCzuY2rc3f1Lv3fkp4s2EC6Uf2yPHwpDe5JkC4h3U76VnR/nufYBrXXzmcSKUwG8vb7MA2euMjD9sjtrXtTtNL+6mtFZfxk0pnjw6TrvcfVvP+4PPxh0o3Dya2+t2Y+40k3H9dT/ymXj+ft/ADp5uV/s+newg7Afw2Oz8OOIX2d35D3jc8BFzZY9mzSUy6n5fn/BnjjSNY5Wx4nF7DpJuBmdeb+q0n3nh4iHSOHNKhxP9KTYhtJJ18n16yfFeRjL/cvrLaX9JTQGlp4yiW3qXafuGCIbXdUrn096Rj5OjChUtfgUy7rSZdbx1feexLp0srgMVzNiP1J92nW5doXNGjbzFzjWIaRC41eg09g2DBIehHpINkzergClZ7nv5t0A+XxXtVhvSNpNikgZvS6ltJIWkH64P1er2tplX/1f5jy17d3A+f1MszNzGo50IdB0rNJX72mkS4LmZltNXzJxcysED5DNzMrxKj+oaopU6bEzJkzR3ORZmbbvBtvvPGBiOhrNt2oBvrMmTNZtmzZaC7SzGybJ6ml35D1JRczs0I40M3MCuFANzMrhAPdzKwQDnQzs0K09JRL/psGG0h/KfHxiOjPf33sUtIfl1kBHBsR67pTppmZNTOcM/SXRMSBEdGf+xcA10bEPqS/Krag49WZmVnL2rnkMof05yTJP+e2X46ZmY1Uq4EewHcl3Shpfh42NSJW5+41wNR6b5Q0X9IyScsGBgbaLNfMzBpp9TdFD4mIVZKeBiyR9KvqyIgISXX/yldELAIWAfT39/svgZmZdUlLZ+gRsSr/XAtcDhwE3C9pGkD+ubZbRZqZWXNNAz3/n70Jg93AS0n/5PZKYPC/z88j/QsvMzPrkVYuuUwFLpc0OP3FEXG1pBuAyySdSPr/h8d2r0wzM2umaaBHxF3AAXWG/xY4vBtFmZnZ8Pk3Rc3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQLQe6pDGSbpJ0Ve7fS9L1kpZLulTSDt0r08zMmhnOGfq7gdsq/WcB50TE3sA64MROFmZmZsPTUqBLmgG8Ajgv9ws4DPhGnmQxMLcbBZqZWWtaPUM/F3g/8OfcvyuwPiIez/0rgen13ihpvqRlkpYNDAy0VayZmTXWNNAlvRJYGxE3jmQBEbEoIvojor+vr28kszAzsxaMbWGaFwKvknQ0MA7YBfgMMFHS2HyWPgNY1b0yzcysmaZn6BFxakTMiIiZwOuA70fE8cB1wDF5snnAFV2r0szMmmrnOfQPAO+TtJx0Tf38zpRkZmYj0collydExFJgae6+Czio8yWZmdlI+DdFzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MytE00CXNE7STyT9TNKtks7Iw/eSdL2k5ZIulbRD98s1M7NGWjlD/wNwWEQcABwIHCXpr4CzgHMiYm9gHXBi98o0M7NmmgZ6JBtz7/b5FcBhwDfy8MXA3K5UaGZmLWnpGrqkMZJuBtYCS4A7gfUR8XieZCUwvTslmplZK1oK9Ij4U0QcCMwADgKe1eoCJM2XtEzSsoGBgRGWaWZmzQzrKZeIWA9cB7wAmChpbB41A1jV4D2LIqI/Ivr7+vraKtbMzBpr5SmXPkkTc/dOwJHAbaRgPyZPNg+4oltFmplZc2ObT8I0YLGkMaQPgMsi4ipJvwQukfQx4Cbg/C7WaWZmTTQN9Ij4OfC8OsPvIl1PNzOzrYB/U9TMrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK4UA3MyuEA93MrBAOdDOzQjjQzcwK0TTQJe0u6TpJv5R0q6R35+GTJS2RdEf+Oan75ZqZWSOtnKE/DpwcEbOAvwLeKWkWsAC4NiL2Aa7N/WZm1iNNAz0iVkfET3P3BuA2YDowB1icJ1sMzO1WkWZm1tywrqFLmgk8D7gemBoRq/OoNcDUjlZmZmbD0nKgS3oK8E3gPRHxUHVcRAQQDd43X9IyScsGBgbaKtbMzBprKdAlbU8K84si4lt58P2SpuXx04C19d4bEYsioj8i+vv6+jpRs5mZ1dHKUy4Czgdui4hPV0ZdCczL3fOAKzpfnpmZtWpsC9O8EHgj8AtJN+dhHwTOBC6TdCJwD3Bsd0o0M7NWNA30iPghoAajD+9sOWZmNlL+TVEzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrhAPdzKwQDnQzs0I40M3MCuFANzMrRNNAl/RlSWsl3VIZNlnSEkl35J+TulummZk108oZ+gXAUTXDFgDXRsQ+wLW538zMeqhpoEfED4Df1QyeAyzO3YuBuR2uy8zMhmmk19CnRsTq3L0GmNpoQknzJS2TtGxgYGCEizMzs2bavikaEQHEEOMXRUR/RPT39fW1uzgzM2tgpIF+v6RpAPnn2s6VZGZmIzHSQL8SmJe75wFXdKYcMzMbqVYeW/wa8L/AvpJWSjoROBM4UtIdwBG538zMemhsswki4vUNRh3e4VrMzKwN/k1RM7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK0RbgS7pKEm3S1ouaUGnijIzs+EbcaBLGgN8Hng5MAt4vaRZnSrMzMyGp50z9IOA5RFxV0T8EbgEmNOZsszMbLjaCfTpwL2V/pV52GYkzZe0TNKygYGBNhZnZmZD6fpN0YhYFBH9EdHf19fX7cWZmT1ptRPoq4DdK/0z8jAzM+uBdgL9BmAfSXtJ2gF4HXBlZ8oyM7PhGjvSN0bE45LeBVwDjAG+HBG3dqwyMzMblhEHOkBEfAf4TodqMTOzNvg3Rc3MCuFANzMrhAPdzKwQiojRW5g0ANwzagvsjCnAA70uYpS5zU8ObvO2Y8+IaPqLPKMa6NsiScsior/XdYwmt/nJwW0ujy+5mJkVwoFuZlYIB3pzi3pdQA+4zU8ObnNhfA3dzKwQPkM3MyuEA93MrBAOdEDSZElLJN2Rf05qMN28PM0dkubVGX+lpFu6X3H72mmzpPGS/kvSryTdKunM0a1+eJr971tJO0q6NI+/XtLMyrhT8/DbJb1sNOtux0jbLOlISTdK+kX+edho1z5S7WznPH4PSRslnTJaNXdcRDzpX8DZwILcvQA4q840k4G78s9JuXtSZfyrgYuBW3rdnm63GRgPvCRPswPwP8DLe92mBu0cA9wJPCPX+jNgVs007wC+mLtfB1yau2fl6XcE9srzGdPrNnW5zc8Ddsvd+wOret2ebre5Mv4bwNeBU3rdnpG+fIaezAEW5+7FwNw607wMWBIRv4uIdcAS4CgASU8B3gd8bBRq7ZQRtzkiHomI6wAi/T/Zn5L+wcnWqJX/fVtdF98ADpekPPySiPhDRNwNLM/z29qNuM0RcVNE3JeH3wrsJGnHUam6Pe1sZyTNBe4mtXmb5UBPpkbE6ty9BphaZ5qh/ofqR4FPAY90rcLOa7fNAEiaCPwNcG03iuyAVv737RPTRMTjwIPAri2+d2vUTpurXgP8NCL+0KU6O2nEbc4nZB8AzhiFOruqrb+Hvi2R9D3g6XVGnVbtiYiQ1PKznJIOBJ4ZEe+tvSbXa91qc2X+Y4GvAZ+NiLtGVqVtjSTtB5wFvLTXtYyChcA5EbExn7Bvs540gR4RRzQaJ+l+SdMiYrWkacDaOpOtAmZX+mcAS4EXAP2SVpDW59MkLY2I2fRYF9s8aBFwR0Sc24Fyu6WV/307OM3K/CH1VOC3Lb53a9ROm5E0A7gceFNE3Nn9cjuinTYfDBwj6WxgIvBnSY9GxOe6X3aH9foi/tbwAv6FzW8Qnl1nmsmka2yT8utuYHLNNDPZdm6KttVm0v2CbwLb9botTdo5lnQzdy823Szbr2aad7L5zbLLcvd+bH5T9C62jZui7bR5Yp7+1b1ux2i1uWaahWzDN0V7XsDW8CJdO7wWuAP4XiW0+oHzKtO9hXRjbDlwQp35bEuBPuI2k85+ArgNuDm/3trrNg3R1qOBX5OegjgtD/sI8KrcPY70dMNy4CfAMyrvPS2/73a20id5Otlm4HTg4cp2vRl4Wq/b0+3tXJnHNh3o/tV/M7NC+CkXM7NCONDNzArhQDczK4QD3cysEA50M7NCONDNzArhQDczK8T/A3fBZq/KKJkNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracies = train()\n",
    "if train_accuracies != None:\n",
    "    plt.plot(train_accuracies)\n",
    "    title = 'Accuracy vs Epochs for: ' + (str)(positive_sample_size+negative_sample_size) + ' data points and ' + (str)(num_epochs) + ' epochs'\n",
    "    plt.title(title)\n",
    "test_accuracy = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_hyperparameters(3, 1000, 50, 0.01)\n",
    "#net = Net()\n",
    "train()\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
